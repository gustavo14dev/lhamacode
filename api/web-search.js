// API endpoint para pesquisa na web
export default async function handler(req, res) {
    // Configurar CORS
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
    res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

    if (req.method === 'OPTIONS') {
        return res.status(200).end();
    }

    if (req.method !== 'POST') {
        return res.status(405).json({ error: 'Method not allowed' });
    }

    const { message, conversationHistory = [] } = req.body;

    // Valida√ß√µes seguras
    if (!message || typeof message !== 'string' || message.trim().length === 0) {
        return res.status(400).json({ error: 'Message is required and must be a non-empty string' });
    }

    // Validar conversationHistory
    if (!Array.isArray(conversationHistory)) {
        console.warn('‚ö†Ô∏è conversationHistory n√£o √© um array, usando array vazio');
        req.body.conversationHistory = [];
    }

    console.log('üîç Recebida requisi√ß√£o de pesquisa:', { 
        message: message?.substring(0, 100) + '...', 
        historyLength: conversationHistory?.length || 0 
    });

    try {
        const response = await callGroqWithBrowserSearch(message, conversationHistory);

        console.log('‚úÖ Resposta da pesquisa gerada');

        return res.status(200).json({
            response: response,
            timestamp: new Date().toISOString()
        });

    } catch (error) {
        console.error('‚ùå Erro na API de pesquisa:', error);
        return res.status(500).json({ 
            error: 'Internal server error',
            message: error.message 
        });
    }
}

async function callGroqWithBrowserSearch(message, conversationHistory) {
    const GROQ_API_KEY = process.env.GROQ_API_KEY;
    
    if (!GROQ_API_KEY) {
        // Fallback quando n√£o h√° API key
        return `üîç **Pesquisa Simulada**

Voc√™ perguntou: "${message}"

[fonte: Simula√ß√£o Local]

*Esta √© uma resposta simulada porque a API Groq n√£o est√° configurada. Para testar com pesquisa real, configure a GROQ_API_KEY no ambiente.*

**Como configurar:**
1. Obtenha uma chave em https://console.groq.com
2. Adicione GROQ_API_KEY= sua_chave ao ambiente
3. Reinicie o servidor

[fonte: Documenta√ß√£o Drekee AI]`;
    }

    console.log('üîç Iniciando chamada para Groq API...');

    // Verificar se √© uma pergunta de acompanhamento
    const isFollowUp = conversationHistory?.length > 0 && (
        message?.toLowerCase()?.includes('explique mais') ||
        message?.toLowerCase()?.includes('detalhe') ||
        message?.toLowerCase()?.includes('pode falar mais') ||
        message?.toLowerCase()?.includes('me diga mais') ||
        message?.toLowerCase()?.includes('amplie') ||
        message?.toLowerCase()?.includes('aprofunde')
    );

    let systemPrompt;

    if (isFollowUp) {
        // Modo de conversa√ß√£o (sem pesquisa)
        systemPrompt = {
            role: 'system',
            content: `Voc√™ √© o Drekee AI 1, um assistente inteligente brasileiro. Continue a conversa baseado no contexto anterior.

REGRAS:
1. RESPONDA SEMPRE EM PORTUGU√äS BRASILEIRO
2. Use linguagem natural e informal
3. Seja direto e claro
4. Use formata√ß√£o simples: **negrito**, *it√°lico*, listas
5. N√ÉO pesquise na web - use apenas seu conhecimento
6. Mantenha o contexto da conversa anterior
7. N√£o adicione fontes (n√£o h√° pesquisa nova)

CONTEXTO ANTERIOR:
${conversationHistory?.map(msg => `${msg?.role}: ${msg?.content}`)?.filter(Boolean)?.join('\n\n') || 'Nenhum contexto anterior.'}`
        };
    } else {
        // Modo de pesquisa web
        systemPrompt = {
            role: 'system',
            content: `Voc√™ √© o Drekee AI 1, um assistente de pesquisa inteligente brasileiro com acesso √† web em tempo real. Sua especialidade √© encontrar informa√ß√µes atuais e apresent√°-las de forma **visualmente rica** e **interativa** para usu√°rios brasileiros.

üé® **FORMATOS AVAN√áADOS DISPON√çVEIS:**

üìä **Tabelas Comparativas:**
| Caracter√≠stica | Op√ß√£o A | Op√ß√£o B |
| :--- | :--- | :--- |
| Pre√ßo | R$ 100 | R$ 200 |
| Qualidade | Alta | Premium |

üìã **Cards de Informa√ß√£o:**
[info: Informa√ß√£o importante para o usu√°rio]
[warning: Alerta ou cuidado necess√°rio]
[success: Resultado positivo ou confirma√ß√£o]
[error: Erro ou problema a evitar]

üìà **Cards de Dados:**
[data: Crescimento | 85%]
[data: Usu√°rios | 2.5M]

üè∑Ô∏è **Tags e Badges:**
[tag: tecnologia]
[badge: exclusivo]

üìä **Barras de Progresso:**
[progress: 75% | Ado√ß√£o no mercado]
[progress: 30% | Conclus√£o do projeto]

‚ú® **Listas Interativas:**
1. **T√≠tulo:** Descri√ß√£o detalhada do item
- **Conceito:** Explica√ß√£o clara e objetiva

üéØ **Formata√ß√µes Tradicionais:**
- **negrito** para palavras importantes
- *it√°lico* para √™nfase
- __sublinhado__ para destaques especiais
- [destaque: palavra-chave] para cards de destaque
- [card: conceito] para cards informativos
- Emojis: :rocket:, :fire:, :star:, :check:, :warning:, :info:, :error:, :success:, :chart:, :trophy:

üìã **ESTRUTURA IDEAL DA RESPOSTA:**
1. **T√≠tulo principal** usando ##
2. **Cards de informa√ß√£o** para dados importantes
3. **Tabelas** para compara√ß√µes
4. **Listas interativas** para explica√ß√µes
5. **Dados destacados** com cards [data:]
6. **Progress bars** para estat√≠sticas
7. **Tags** para categoriza√ß√£o
8. **Fontes** no final: Fonte: Site ‚Äì "T√≠tulo" (data)

üéØ **EXEMPLO COMPLETO:**
## An√°lise de Mercado 2024

[info: O mercado de tecnologia cresceu 23% este ano]

üìä **Comparativo de Crescimento:**
| Setor | 2023 | 2024 |
| :--- | :--- | :--- |
| IA | 45% | 68% |
| Cloud | 32% | 41% |

[data: Investimento Total | R$ 8.5B]
[progress: 68% | Meta de Crescimento]

1. **Intelig√™ncia Artificial:** Liderou o crescimento com machine learning avan√ßado
- **Machine Learning:** Processamento de big data em tempo real
- **Automa√ß√£o:** Redu√ß√£o de custos operacionais

[tag: inova√ß√£o] [badge: tend√™ncia] [destaque: alta demanda]

üî• **USE SEMPRE FORMATA√á√ïES RICAS!** Torn sua resposta visualmente impactante e f√°cil de entender!`
        };
    }

    // Construir mensagens com hist√≥rico
    const messages = [
        systemPrompt,
        ...conversationHistory.slice(-4), // √öltimas 4 mensagens para contexto
        {
            role: 'user',
            content: message
        }
    ];

    // Tentar com modelo principal
    try {
        console.log('üì° Tentando modelo principal: openai/gpt-oss-120b');
        return await callWithMainModel(message, systemPrompt, messages);
    } catch (error) {
        console.log('‚ö†Ô∏è Modelo principal falhou, tentando fallback:', error.message);
        try {
            console.log('üì° Tentando modelo fallback: llama-3.1-8b-instant');
            return await callWithFallbackModel(message, systemPrompt);
        } catch (fallbackError) {
            console.log('‚ùå Todos os modelos falharam:', fallbackError.message);
            throw new Error(`Todos os modelos de pesquisa falharam: ${fallbackError.message}`);
        }
    }
}

async function callWithMainModel(message, systemPrompt, messages) {
    const GROQ_API_KEY = process.env.GROQ_API_KEY;
    
    const requestBody = {
        model: 'openai/gpt-oss-120b',
        messages: messages,
        temperature: 0.3, // Menos criatividade, mais precis√£o
        max_tokens: 4096,
        top_p: 0.9,
        stream: false,
        tool_choice: "required",
        tools: [
            {
                type: "browser_search"
            }
        ]
    };

    console.log('üì° Enviando requisi√ß√£o para Groq com browser search...');

    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${GROQ_API_KEY}`,
            'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Erro na API Groq:', response.status, errorText);
        
        // Tentar com modelo menor se o 70B falhar
        if (response.status === 429 || response.status === 502) {
            console.log('üîÑ Tentando com modelo menor...');
            return await callWithSmallerModel(message, systemPrompt);
        }
        
        throw new Error(`Groq API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
        throw new Error('Resposta inv√°lida da API Groq');
    }

    const content = data.choices[0].message.content;
    console.log('‚úÖ Resposta recebida do Groq');
    
    return content;
}

async function callWithSmallerModel(message, systemPrompt) {
    const GROQ_API_KEY = process.env.GROQ_API_KEY;
    
    const requestBody = {
        model: 'llama-3.1-8b-instant',
        messages: [
            systemPrompt,
            { role: 'user', content: message }
        ],
        temperature: 0.3,
        max_tokens: 2048,
        top_p: 0.9,
        stream: false,
        tool_choice: "required",
        tools: [
            {
                type: "browser_search"
            }
        ]
    };

    console.log('üì° Enviando requisi√ß√£o para Groq com modelo fallback...');

    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${GROQ_API_KEY}`,
            'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Erro na API Groq (fallback):', response.status, errorText);
        throw new Error(`Groq API error (fallback): ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
        throw new Error('Resposta inv√°lida da API Groq (fallback)');
    }

    console.log('‚úÖ Resposta recebida do modelo fallback');
    return data.choices[0].message.content;
}
